{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(1)\n",
    "import string     \n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/Riniperencsik/Desktop/Projects/Twitter Sentiment Analysis/twitter_airlines_data.csv\", encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the tweets based on their sentiment\n",
    "\n",
    "data = data[['airline_sentiment', \"text\"]]\n",
    "positive_tweets = list(data[data['airline_sentiment']=='positive']['text'])\n",
    "negative_tweets = list(data[data['airline_sentiment']=='negative']['text'])\n",
    "neutral_tweets = list(data[data['airline_sentiment']=='neutral']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# create test sets and training sets\n",
    "# we want to keep the distribution of classes the same for both sets\n",
    "\n",
    "neutral_train = neutral_tweets[:2480] # 2480 is 80% of the neutral tweets\n",
    "\n",
    "negative_train = negative_tweets[:7343] # 7343 is 80% of the negative tweets\n",
    "\n",
    "positive_train = positive_tweets[:1891] # 1891 is 80% of the positive tweets\n",
    "\n",
    "train = positive_train + negative_train + neutral_train\n",
    "\n",
    "\n",
    "labels_train = [] # create the labels for each tweet\n",
    "\n",
    "for i in range(2480): # 0 for neutral\n",
    "    labels_train.append(0)\n",
    "    \n",
    "for i in range(7343): # 1 for negative\n",
    "    labels_train.append(1)\n",
    "    \n",
    "for i in range(1891): # 2 for positive\n",
    "    labels_train.append(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_test = neutral_tweets[2480:] # 20% of the neutral tweets\n",
    "\n",
    "negative_test = negative_tweets[7343:] # 20% of the negative tweets\n",
    "\n",
    "positive_test = positive_tweets[1891:] # 20% of the positive tweets\n",
    "\n",
    "test = positive_test + negative_test + neutral_test\n",
    "\n",
    "\n",
    "labels_test = [] # create the labels for each tweet\n",
    "\n",
    "for i in range(2480, 3099): # 0 for neutral\n",
    "    labels_test.append(0)\n",
    "    \n",
    "for i in range(7343, 9178): # 1 for negative\n",
    "    labels_test.append(1)\n",
    "    \n",
    "for i in range(1891, 2363): # 2 for positive\n",
    "    labels_test.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one hot vector so that it can be processed by RNN\n",
    "\n",
    "labels_train = to_categorical(labels_train)\n",
    "\n",
    "labels_test = to_categorical(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras requires that the input data be integer encoded so that each words is represented by a unique integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the tweets to an integer encoded version  \n",
    "# one_hot() creates hash of each word\n",
    "\n",
    "# for training set\n",
    "train_encoded = [one_hot(d,10000) for d in train]\n",
    "\n",
    "# for test set\n",
    "test_encoded = [one_hot(d, 10000) for d in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest tweet has 50 number of words\n"
     ]
    }
   ],
   "source": [
    "# keras prefers inputs vectroized and all the same length so we must pad\n",
    "\n",
    "# find the maxmimum number of words in one tweet\n",
    "\n",
    "largest = len(test_encoded[0])\n",
    "\n",
    "for tweet in test_encoded:\n",
    "    if len(tweet) > largest:\n",
    "        largest = len(tweet)\n",
    "        \n",
    "print(\"The longest tweet has {:d} number of words\".format(largest))\n",
    "\n",
    "max_tweet_length = largest\n",
    "\n",
    "\n",
    "train_encoded = sequence.pad_sequences(train_encoded, maxlen = max_tweet_length)\n",
    "\n",
    "# repeat for test set\n",
    "\n",
    "max_tweet_length = largest\n",
    "test_encoded = sequence.pad_sequences(test_encoded, maxlen = max_tweet_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "The callbacks already being used: \n",
    "- BaseLogger: Callback that accumulates epoch average of metrics\n",
    "- ProgbadLogger: Callback that prints metrics to stdout\n",
    "- History: Callback that records events into a history object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Riniperencsik/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n",
      "/Users/Riniperencsik/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/tensorboard_v2.py:102: UserWarning: The TensorBoard callback does not support embeddings display when using TensorFlow 2.0. Embeddings-related arguments are ignored.\n",
      "  warnings.warn('The TensorBoard callback does not support '\n"
     ]
    }
   ],
   "source": [
    "# verbose 0: silent, doesnt show anything\n",
    "# verbose 1: shows you progress bad\n",
    "# verbose 2: shows one line per epoch\n",
    "\n",
    "# check it out on keras, if u dont know how many epochs to do with model checkpoint, u can save on the best loss its ever seen or best validation accuracy its ever seen\n",
    "\n",
    "# saves a model or weights at some interval so the model can be loaded later to continue training from the state saved\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "mc = ModelCheckpoint(\n",
    "    filepath = \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\", # what to put here?\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 0,\n",
    "    save_best_only = True, # least loss... as opposed to saving each model at the end of each epoch\n",
    "    save_weights_only = True, #\n",
    "    mode = 'min') # min bc we want to minimize loss. max is for val_acc\n",
    "\n",
    "\n",
    "# stops training when a monitored metric has stopped improving\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor = 'val_loss', # monitor the loss\n",
    "    min_delta = 0.01, # wait patience periods for it to do better by the min delta, if it does not then stops training\n",
    "    patience = 2, # number of epochs with no improvement\n",
    "    verbose = 1, \n",
    "    mode = 'min')\n",
    "\n",
    "#from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "#lrs = LearningRateScheduler(lambda epoch: 1./epoch) # at the end of each epoch change the learning rate \n",
    "\n",
    "\n",
    "# reduce learning rate when a metric has stopped improving \n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau # hardly uses this\n",
    "\n",
    "# models often benefit from reducing the learning rate once learning stagnates\n",
    "rlrop = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss',\n",
    "    factor = 0.1,\n",
    "    patience = 2, # if model does not see improvement by epsilon after 2 epochs then reduce the learning rate\n",
    "    verbose = 0,\n",
    "    mode = 'min',\n",
    "    epsilon = 0.0001,\n",
    "    cooldown = 2, # wait 2 epochs before monitoring the metrics again\n",
    "    min_lr = 0 # minimum learning rate\n",
    " )\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "import datetime, os\n",
    "# https://pythonprogramming.net/tensorboard-analysis-deep-learning-python-tensorflow-keras/\n",
    "# allows to visualize training over time\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tb = TensorBoard(\n",
    "    log_dir =logdir,\n",
    "    histogram_freq = 1, # histogram computation\n",
    "    write_graph = True, \n",
    "    write_images = False, \n",
    "    embeddings_freq = 100,\n",
    "    embeddings_layer_names = None, \n",
    "    embeddings_metadata = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer #1: Word Embeddings\n",
    "\n",
    "Word embeddings provide a vector representation of words and their relative meanings. They can be learned from alternative text data and be resued in following models. There are carefully designed methods of learning word embeddings such as word2vec. Keras supports word embeddings through the embedding layer. Additionally, they can also be learned as part of fitting a Neural Network on text data. Through this layer, the position of a word within the vector space is learned from text and is based on the words that surround the word when it is used. The embedding layer is initialized with random weights and will learn an embedding for all the words. The output of this layer is a 2D vector with one embedding for each word in the input sequence of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer #2: LSTM\n",
    "\n",
    "Simple RNNs suffer from the vanishing gradient problem where information from previous layers gets lost as the network deepens. An LSTM algorithm was created to avoid this problem by allowing the neural network to carry information across multiple steps. Additionally, an LSTM cell can determine what information to remove as well. Therefore, it can learn to recognize an important input and store it for the future while removing usless information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "The intuition behind the dropout layer is that any one feature cannot be relied on, so the weights must be spread out. Dropout randomly knocks out units in your network so it is as if on every iteration, you are working with a smaller neural network which should have a regularizing effect. If overfitting is a problem in a layer (when the layer has a lot of parameters), you can decrease the keep probability. The downside is that the cost function is less defined and harder to calculate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: \n",
    "\n",
    "Momentum - If there is a large learning rate, it might overshoot the optimal value. Momentum smoothes out the steps of gradient descent and allows the algorithm to take a more straightforward path using moving averages. It almost always works better than without momentum and speeds up the algorithm.\n",
    "\n",
    "RMSprop - Helps to speed up gradient descent. The net effect of this is that your updates in the vertical direction are divided by a much larger number so that helps dampen out the oscillations. \n",
    "\n",
    "Adam Optimization - combines momentum and RMSprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classification:\n",
    "\n",
    "Softmax is a generalization of logistic regression that allows for multi-class predictions. Use it in the last layer to generate outputs. It outputs a probability for each class and th loss fucntion tries to make the correct probability as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Decay\n",
    "\n",
    "Implemented a learning rate decay upon plateau earlier. This helps the problem of local optima. Gradient descent can get stuck in local optima. Plateaus can really slow down learning (which adam can help speed up) when the gradient is close to 0. It is unlikley to get stuck in a local optima so long as yu are training a lage n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               279552    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 440,323\n",
      "Trainable params: 440,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Riniperencsik/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11714 samples, validate on 2926 samples\n",
      "Epoch 1/10\n",
      "11714/11714 [==============================] - 125s 11ms/step - loss: 0.8784 - accuracy: 0.6300 - val_loss: 0.8215 - val_accuracy: 0.6394\n",
      "Epoch 2/10\n",
      "11714/11714 [==============================] - 113s 10ms/step - loss: 0.7369 - accuracy: 0.6776 - val_loss: 0.7834 - val_accuracy: 0.6774\n",
      "Epoch 3/10\n",
      "11714/11714 [==============================] - 89s 8ms/step - loss: 0.6623 - accuracy: 0.7237 - val_loss: 0.7900 - val_accuracy: 0.6955\n",
      "Epoch 4/10\n",
      "11714/11714 [==============================] - 97s 8ms/step - loss: 0.5942 - accuracy: 0.7659 - val_loss: 0.7935 - val_accuracy: 0.7157\n",
      "Epoch 00004: early stopping\n",
      "<keras.callbacks.callbacks.History object at 0x1a42c26d10>\n"
     ]
    }
   ],
   "source": [
    "# model down here\n",
    "\n",
    "model = keras.Sequential() # sequential groups a stack of layers\n",
    "\n",
    "model.add(keras.layers.Embedding(10000, 16)) \n",
    "\n",
    "# dropout is a regularization technique that aims to reduce the complexity of the model to prevent overfitting\n",
    "# with dropout, you randomly deactivate certain neurons, layer needs to be tuned\n",
    "model.add(keras.layers.LSTM(256, dropout = 0.5))\n",
    "\n",
    "# a dropout layer is a fully connected nn layer where each input node is connected to each output node\n",
    "model.add(keras.layers.Dense(3, activation = \"softmax\")) # common to put dense layer before output\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"]) # look up optimizer and loss\n",
    "\n",
    "fitModel = model.fit(train_encoded, \n",
    "                     labels_train, \n",
    "                     epochs =10, \n",
    "                     batch_size = 128, # not using full batch since num samples > 2000\n",
    "                     validation_data = (test_encoded, labels_test), \n",
    "                     verbose = 1,\n",
    "                    callbacks = [tb, mc, es, rlrop])\n",
    "\n",
    "print(fitModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8119\n",
      "Testing Accuracy:  0.7157\n"
     ]
    }
   ],
   "source": [
    "# Find train and test accuracy\n",
    "# train accuracy originally 0.91, test = 0.69\n",
    "\n",
    "#after removing the recurrent unit drop out, test accuracy increased 2%\n",
    "loss, accuracy = model.evaluate(train_encoded, labels_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(test_encoded, labels_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot train/test loss and accuracy\n",
    "acc = fitModel.history['accuracy']\n",
    "val_acc = fitModel.history['val_accuracy']\n",
    "loss = fitModel.history['loss']\n",
    "val_loss = fitModel.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Reduced Dimenstionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                20736     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 180,931\n",
      "Trainable params: 180,931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Riniperencsik/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11714 samples, validate on 2926 samples\n",
      "Epoch 1/10\n",
      "11714/11714 [==============================] - 40s 3ms/step - loss: 0.8906 - accuracy: 0.6311 - val_loss: 0.8104 - val_accuracy: 0.6541\n",
      "Epoch 2/10\n",
      "11714/11714 [==============================] - 31s 3ms/step - loss: 0.7461 - accuracy: 0.6801 - val_loss: 0.8063 - val_accuracy: 0.6651\n",
      "Epoch 3/10\n",
      "11714/11714 [==============================] - 30s 3ms/step - loss: 0.6706 - accuracy: 0.7228 - val_loss: 0.7671 - val_accuracy: 0.6992\n",
      "Epoch 4/10\n",
      "11714/11714 [==============================] - 31s 3ms/step - loss: 0.5924 - accuracy: 0.7733 - val_loss: 0.7902 - val_accuracy: 0.7129\n",
      "Epoch 5/10\n",
      "11714/11714 [==============================] - 31s 3ms/step - loss: 0.5210 - accuracy: 0.8051 - val_loss: 0.7772 - val_accuracy: 0.7177\n",
      "Epoch 00005: early stopping\n",
      "<keras.callbacks.callbacks.History object at 0x1a539ecf90>\n"
     ]
    }
   ],
   "source": [
    "# reduce dimensionality\n",
    "\n",
    "model2 = keras.Sequential() # sequential groups a stack of layers\n",
    "\n",
    "model2.add(keras.layers.Embedding(10000, 16)) \n",
    "\n",
    "# dropout is a regularization technique that aims to reduce the complexity of the model to prevent overfitting\n",
    "# with dropout, you randomly deactivate certain neurons, layer needs to be tuned\n",
    "model2.add(keras.layers.LSTM(64, dropout = 0.5))\n",
    "\n",
    "# a dropout layer is a fully connected nn layer where each input node is connected to each output node\n",
    "model2.add(keras.layers.Dense(3, activation = \"softmax\")) # common to put dense layer before output\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "model2.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"]) # look up optimizer and loss\n",
    "\n",
    "fitModel2 = model2.fit(train_encoded, \n",
    "                     labels_train, \n",
    "                     epochs =10, \n",
    "                     batch_size = 128, \n",
    "                     validation_data = (test_encoded, labels_test), \n",
    "                     verbose = 1,\n",
    "                    callbacks = [tb, mc, es, rlrop])\n",
    "\n",
    "print(fitModel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8463\n",
      "Testing Accuracy:  0.7177\n"
     ]
    }
   ],
   "source": [
    "# Find train and test accuracy\n",
    "# train accuracy originally 0.91, test = 0.69\n",
    "loss, accuracy = model2.evaluate(train_encoded, labels_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model2.evaluate(test_encoded, labels_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "\n",
    "#test accuracy improved with dimenstionality deduction, although overfitting increased. must increase dropout percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Increased Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.65 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.65 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.65 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.65 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                20736     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 180,931\n",
      "Trainable params: 180,931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Riniperencsik/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11714 samples, validate on 2926 samples\n",
      "Epoch 1/10\n",
      "11714/11714 [==============================] - 36s 3ms/step - loss: 0.9182 - accuracy: 0.6247 - val_loss: 0.8267 - val_accuracy: 0.6381\n",
      "Epoch 2/10\n",
      "11714/11714 [==============================] - 30s 3ms/step - loss: 0.7725 - accuracy: 0.6649 - val_loss: 0.7931 - val_accuracy: 0.6702\n",
      "Epoch 3/10\n",
      "11714/11714 [==============================] - 33s 3ms/step - loss: 0.7011 - accuracy: 0.7089 - val_loss: 0.7983 - val_accuracy: 0.6883\n",
      "Epoch 4/10\n",
      "11714/11714 [==============================] - 30s 3ms/step - loss: 0.6424 - accuracy: 0.7446 - val_loss: 0.7888 - val_accuracy: 0.6941\n",
      "Epoch 00004: early stopping\n",
      "<keras.callbacks.callbacks.History object at 0x1a563bbdd0>\n"
     ]
    }
   ],
   "source": [
    "# increase dropout\n",
    "# reduce dimensionality\n",
    "\n",
    "model3 = keras.Sequential() # sequential groups a stack of layers\n",
    "\n",
    "model3.add(keras.layers.Embedding(10000, 16)) \n",
    "\n",
    "# dropout is a regularization technique that aims to reduce the complexity of the model to prevent overfitting\n",
    "# with dropout, you randomly deactivate certain neurons, layer needs to be tuned\n",
    "model3.add(keras.layers.LSTM(64, dropout = 0.65))\n",
    "\n",
    "# a dropout layer is a fully connected nn layer where each input node is connected to each output node\n",
    "model3.add(keras.layers.Dense(3, activation = \"softmax\")) # common to put dense layer before output\n",
    "\n",
    "print(model3.summary())\n",
    "\n",
    "model3.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"]) # look up optimizer and loss\n",
    "\n",
    "fitModel3 = model3.fit(train_encoded, \n",
    "                     labels_train, \n",
    "                     epochs =10, \n",
    "                     batch_size = 128, \n",
    "                     validation_data = (test_encoded, labels_test), \n",
    "                     verbose = 1,\n",
    "                    callbacks = [tb, mc, es, rlrop])\n",
    "\n",
    "print(fitModel3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7995\n",
      "Testing Accuracy:  0.6941\n"
     ]
    }
   ],
   "source": [
    "# Find train and test accuracy\n",
    "# train accuracy originally 0.91, test = 0.69\n",
    "loss, accuracy = model3.evaluate(train_encoded, labels_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model3.evaluate(test_encoded, labels_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "\n",
    "# test accuracy worsened as a result of increasing dropout rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Batch Normalization\n",
    "\n",
    "Batch Normalization helps to speed up learning by making it so that the inputs take on a similar range of values. It makes hyperparameter search much easier, NN much more robust to the choice of hyperparamters, and easier to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 64)                20736     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 180,943\n",
      "Trainable params: 180,937\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Riniperencsik/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11714 samples, validate on 2926 samples\n",
      "Epoch 1/10\n",
      "11714/11714 [==============================] - 43s 4ms/step - loss: 0.9818 - accuracy: 0.5656 - val_loss: 1.0153 - val_accuracy: 0.6535\n",
      "Epoch 2/10\n",
      "11714/11714 [==============================] - 33s 3ms/step - loss: 0.8004 - accuracy: 0.6868 - val_loss: 0.9368 - val_accuracy: 0.7023\n",
      "Epoch 3/10\n",
      "11714/11714 [==============================] - 34s 3ms/step - loss: 0.6742 - accuracy: 0.7574 - val_loss: 0.9693 - val_accuracy: 0.5513\n",
      "Epoch 4/10\n",
      "11714/11714 [==============================] - 36s 3ms/step - loss: 0.5868 - accuracy: 0.7922 - val_loss: 0.8007 - val_accuracy: 0.6606\n",
      "Epoch 5/10\n",
      "11714/11714 [==============================] - 35s 3ms/step - loss: 0.5155 - accuracy: 0.8254 - val_loss: 0.7385 - val_accuracy: 0.7071\n",
      "Epoch 6/10\n",
      "11714/11714 [==============================] - 40s 3ms/step - loss: 0.4674 - accuracy: 0.8466 - val_loss: 0.8988 - val_accuracy: 0.6183\n",
      "Epoch 7/10\n",
      "11714/11714 [==============================] - 32s 3ms/step - loss: 0.4212 - accuracy: 0.8655 - val_loss: 0.7658 - val_accuracy: 0.6996\n",
      "Epoch 00007: early stopping\n",
      "<keras.callbacks.callbacks.History object at 0x1a5ff41e90>\n"
     ]
    }
   ],
   "source": [
    "# Batch Normalization\n",
    "\n",
    "model3 = keras.Sequential() # sequential groups a stack of layers\n",
    "\n",
    "model3.add(keras.layers.Embedding(10000, 16)) \n",
    "\n",
    "# dropout is a regularization technique that aims to reduce the complexity of the model to prevent overfitting\n",
    "# with dropout, you randomly deactivate certain neurons, layer needs to be tuned\n",
    "model3.add(keras.layers.LSTM(64, dropout = 0.5))\n",
    "\n",
    "# a dropout layer is a fully connected nn layer where each input node is connected to each output node\n",
    "model3.add(keras.layers.Dense(3))# common to put dense layer before output\n",
    "model3.add(keras.layers.BatchNormalization())\n",
    "model3.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "print(model3.summary())\n",
    "\n",
    "model3.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"]) # look up optimizer and loss\n",
    "\n",
    "fitModel3 = model3.fit(train_encoded, \n",
    "                     labels_train, \n",
    "                     epochs =10, \n",
    "                     batch_size = 128, \n",
    "                     validation_data = (test_encoded, labels_test), \n",
    "                     verbose = 1,\n",
    "                    callbacks = [tb, mc, es, rlrop])\n",
    "\n",
    "print(fitModel3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9200\n",
      "Testing Accuracy:  0.6921\n"
     ]
    }
   ],
   "source": [
    "# Find train and test accuracy\n",
    "# train accuracy originally 0.91, test = 0.69\n",
    "loss, accuracy = model3.evaluate(train_encoded, labels_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model3.evaluate(test_encoded, labels_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "# test accuracy worsened as a result of batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with Batch Normalization after Activation Layer - NaN Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                20736     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 180,943\n",
      "Trainable params: 180,937\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Riniperencsik/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11714 samples, validate on 2926 samples\n",
      "Epoch 1/10\n",
      "11714/11714 [==============================] - 51s 4ms/step - loss: nan - accuracy: 0.2162 - val_loss: nan - val_accuracy: 0.2116\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: embedding_10/embeddings_0 [Op:WriteHistogramSummary] name: embedding_10/embeddings_0/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-aa0f2c0fb20d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m                      \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                      \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     callbacks = [tb, mc, es, rlrop])\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitModel4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_log_weights\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m   1692\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m           \u001b[0msummary_ops_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_weight_as_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(name, tensor, family, step)\u001b[0m\n\u001b[1;32m    799\u001b[0m         name=scope)\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msummary_writer_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36msummary_writer_function\u001b[0;34m(name, tensor, function, family)\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     op = smart_cond.smart_cond(\n\u001b[0;32m--> 730\u001b[0;31m         should_record_summaries(), record, _nothing, name=\"\")\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mrecord\u001b[0;34m()\u001b[0m\n\u001b[1;32m    721\u001b[0m     with ops.name_scope(name_scope), summary_op_util.summary_scope(\n\u001b[1;32m    722\u001b[0m         name, family, values=[tensor]) as (tag, scope):\n\u001b[0;32m--> 723\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/summary_ops_v2.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(tag, scope)\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         name=scope)\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msummary_writer_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_summary_ops.py\u001b[0m in \u001b[0;36mwrite_histogram_summary\u001b[0;34m(writer, step, tag, values, name)\u001b[0m\n\u001b[1;32m    584\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         return write_histogram_summary_eager_fallback(\n\u001b[0;32m--> 586\u001b[0;31m             writer, step, tag, values, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m    587\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_summary_ops.py\u001b[0m in \u001b[0;36mwrite_histogram_summary_eager_fallback\u001b[0;34m(writer, step, tag, values, name, ctx)\u001b[0m\n\u001b[1;32m    620\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m   _result = _execute.execute(b\"WriteHistogramSummary\", 0, inputs=_inputs_flat,\n\u001b[0;32m--> 622\u001b[0;31m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m    623\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: embedding_10/embeddings_0 [Op:WriteHistogramSummary] name: embedding_10/embeddings_0/"
     ]
    }
   ],
   "source": [
    "# Batch Normalization\n",
    "\n",
    "model4 = keras.Sequential() # sequential groups a stack of layers\n",
    "\n",
    "model4.add(keras.layers.Embedding(10000, 16)) \n",
    "\n",
    "# dropout is a regularization technique that aims to reduce the complexity of the model to prevent overfitting\n",
    "# with dropout, you randomly deactivate certain neurons, layer needs to be tuned\n",
    "model4.add(keras.layers.LSTM(64, dropout = 0.5))\n",
    "\n",
    "# a dropout layer is a fully connected nn layer where each input node is connected to each output node\n",
    "model4.add(keras.layers.Dense(3))# common to put dense layer before output\n",
    "model4.add(keras.layers.Activation('softmax'))\n",
    "model4.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "print(model4.summary())\n",
    "\n",
    "model4.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"]) # look up optimizer and loss\n",
    "\n",
    "fitModel4 = model4.fit(train_encoded, \n",
    "                     labels_train, \n",
    "                     epochs =10, \n",
    "                     batch_size = 128, \n",
    "                     validation_data = (test_encoded, labels_test), \n",
    "                     verbose = 1,\n",
    "                    callbacks = [tb, mc, es, rlrop])\n",
    "\n",
    "print(fitModel4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.2117\n",
      "Testing Accuracy:  0.2116\n"
     ]
    }
   ],
   "source": [
    "# Find train and test accuracy\n",
    "# train accuracy originally 0.91, test = 0.69\n",
    "loss, accuracy = model4.evaluate(train_encoded, labels_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model4.evaluate(test_encoded, labels_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next:\n",
    "\n",
    "- High Bias: bigger network, train longer, more advanced optimization algorithms\n",
    "- Mini batch size\n",
    "- Learning rate: try a range of values for alpha\n",
    "- Number of layers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
